{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshil1450/Harshil/blob/main/FeatureEngineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "\n",
        "A parameter in Machine Learning is a value learned from the training data. These are the internal variables of the model, such as the weights in linear regression or the connections between neurons in a neural network. They are adjusted during training to optimize the model's performance."
      ],
      "metadata": {
        "id": "RI__Ni0JYEEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is correlation?\n",
        "\n",
        "Correlation is a statistical measure that indicates the extent to which two variables change together. It shows the strength and direction of a relationship between variables, ranging from -1 (strong negative relationship) to +1 (strong positive relationship). A correlation of 0 means no relationship."
      ],
      "metadata": {
        "id": "L8VutDhNYKyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What does negative correlation mean?\n",
        "\n",
        "Negative correlation occurs when one variable increases as the other decreases. For example, the amount of time spent studying and the number of mistakes in a test might show a negative correlation: as study time increases, mistakes decrease."
      ],
      "metadata": {
        "id": "FGCaYSrnYNNw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "Machine Learning is a field of artificial intelligence where algorithms are designed to learn patterns and make decisions or predictions based on data, without explicit programming.\n",
        "Main components include:\n",
        "\n",
        "Data: Input information used for training.\n",
        "Model: The mathematical structure used to capture patterns.\n",
        "Training: Process of optimizing parameters based on data.\n",
        "Evaluation: Measuring the model’s performance.\n",
        "Deployment: Using the model for real-world applications."
      ],
      "metadata": {
        "id": "QtBd4nMqYPmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "The loss value quantifies the error between the predicted outputs of the model and the actual target values. A high loss indicates the model's predictions are far from correct, while a low loss suggests better performance. However, overfitting might occur if the loss is too low on the training set but high on the test set."
      ],
      "metadata": {
        "id": "0O3jOs7MYUi6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What are continuous and categorical variables?\n",
        "\n",
        "Continuous variables: Numerical values that can take any value within a range, like temperature, height, or salary.\n",
        "Categorical variables: Variables representing distinct groups or categories, like gender, color, or region."
      ],
      "metadata": {
        "id": "DUKhyCVrYX4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "Categorical variables must be converted into numerical formats. Common techniques include:\n",
        "\n",
        "One-hot encoding: Creates binary columns for each category.\n",
        "Label encoding: Assigns an integer to each category.\n",
        "Target encoding: Replaces categories with a statistical measure (e.g., mean of the target).\n",
        "Binary encoding: Combines label encoding with binary representation."
      ],
      "metadata": {
        "id": "iiJsGGJSYbHe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What do you mean by training and testing a dataset?\n",
        "\n",
        "Training dataset: A portion of the data used to teach the model by finding patterns.\n",
        "Testing dataset: A separate portion used to evaluate how well the trained model generalizes to new data."
      ],
      "metadata": {
        "id": "7urvA4ozYe2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is sklearn.preprocessing?\n",
        "\n",
        "It is a module in scikit-learn that provides tools for preprocessing data. It includes functions for scaling features, encoding categorical data, normalizing data, and generating polynomial features."
      ],
      "metadata": {
        "id": "fiJIs5phYhT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What is a Test set?\n",
        "\n",
        "The test set is a subset of the data reserved exclusively for assessing the model's performance on unseen data. It ensures the model's predictions are evaluated in a fair and unbiased manner."
      ],
      "metadata": {
        "id": "UI4yOsBrYkKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. How do we split data for model fitting (training and testing) in Python?\n",
        "In Python, we use the train_test_split() function from scikit-learn:"
      ],
      "metadata": {
        "id": "saaQR2ngYnBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "T-s65IhfYt2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. How do you approach a Machine Learning problem?\n",
        "\n",
        "\n",
        "*   Understand the problem: Define the objective clearly.\n",
        "\n",
        "*   Collect and prepare data: Gather relevant data and handle missing or inconsistent values.\n",
        "*   EDA: Analyze the data to understand its structure and patterns.\n",
        "*   Preprocessing: Scale, encode, and transform data as needed.\n",
        "*  Model selection: Choose a suitable algorithm.\n",
        "*  Training and tuning: Train the model and optimize hyperparameters.\n",
        "*  Validation: Evaluate the model on validation data.\n",
        "*  Testing and deployment: Test on unseen data and deploy if satisfactory."
      ],
      "metadata": {
        "id": "LbGhR6UQYzhy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "Exploratory Data Analysis (EDA) helps us understand the data's structure, detect outliers, check distributions, and identify missing values. Without EDA, important issues like unbalanced datasets or incorrect assumptions about variables may lead to poor model performance."
      ],
      "metadata": {
        "id": "ba8CZ4tzaVKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What is correlation?\n",
        "\n",
        "Correlation quantifies the degree to which two variables are related. It helps determine whether one variable tends to increase or decrease as the other does.\n",
        "\n"
      ],
      "metadata": {
        "id": "pq7TM3MvblPr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. What does negative correlation mean?\n",
        "\n",
        "Negative correlation indicates an inverse relationship between two variables. For example, as exercise frequency increases, weight might decrease."
      ],
      "metadata": {
        "id": "-GBWYGKRb00z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. How can you find correlation between variables in Python?\n",
        "Use the .corr() method for numerical correlation or visualize it with seaborn.heatmap() for better understanding. Example:"
      ],
      "metadata": {
        "id": "NgfKFnCqb9EZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "correlation_matrix = df.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True)"
      ],
      "metadata": {
        "id": "OY8KyM8ZcCRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What is causation? Explain the difference between correlation and causation with an example.\n",
        "\n",
        "\n",
        "Causation: When one event causes another.\n",
        "\n",
        "Difference: Correlation shows association, while causation implies direct effect.\n",
        "\n",
        "Example: Increased ice cream sales and drowning incidents are correlated due to summer, but buying ice cream doesn’t cause drowning."
      ],
      "metadata": {
        "id": "ayqbUVF4cEXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What is an Optimizer?What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "Optimizers adjust model parameters to minimize the loss function.\n",
        "\n",
        "Common types:\n",
        "\n",
        "SGD: Updates weights using gradients of small data batches.\n",
        "\n",
        "Adam: Combines momentum and adaptive learning rates for efficiency.\n",
        "\n",
        "RMSprop: Scales learning rates based on recent gradient magnitude."
      ],
      "metadata": {
        "id": "OYA95klLcSD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. What is sklearn.linear_model?\n",
        "\n",
        "It is a module in scikit-learn for implementing linear models like LinearRegression, Ridge, Lasso, and LogisticRegression."
      ],
      "metadata": {
        "id": "O3Ms27VHckOF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. What does model.fit() do? What arguments must be given?\n",
        "Trains the model by finding patterns in the data. Arguments:\n",
        "\n",
        "X: Features or input data.\n",
        "\n",
        "y: Target variable or labels."
      ],
      "metadata": {
        "id": "rVeHicgFcpmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What does model.predict() do? What arguments must be given?\n",
        "\n",
        "Generates predictions based on input data. Argument: X (features of new data)."
      ],
      "metadata": {
        "id": "jajE4YM_c44C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. What are continuous and categorical variables?\n",
        "\n",
        "Continuous variables are numerical and take any value (e.g., height). Categorical variables represent distinct groups (e.g., type of car)."
      ],
      "metadata": {
        "id": "LvadPH_9c84I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "Feature scaling normalizes the range of features, making algorithms sensitive to magnitude (e.g., gradient descent or SVM) perform efficiently and comparably."
      ],
      "metadata": {
        "id": "aD8sQTXTdGiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. How do we perform scaling in Python?\n",
        "\n",
        "Use StandardScaler or MinMaxScaler from scikit-learn:\n"
      ],
      "metadata": {
        "id": "p0fPBAoJdQee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "7_XLEyT8dXoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. What is sklearn.preprocessing?\n",
        "It is a scikit-learn module that provides tools for preprocessing data, such as scaling (e.g., StandardScaler), encoding (e.g., OneHotEncoder), normalization, and polynomial feature transformation."
      ],
      "metadata": {
        "id": "qETZ22lzdXES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "26. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "Splitting data involves dividing it into training and testing subsets to ensure the model learns and generalizes effectively. Use the train_test_split function from scikit-learn, where you can control the proportion of test data, randomization, and stratification:\n",
        "python\n",
        "Copy code\n"
      ],
      "metadata": {
        "id": "137WLTNIdt7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "#test_size: Proportion of the data for testing (e.g., 30%).\n",
        "#stratify: Ensures balanced class distribution in training and test sets."
      ],
      "metadata": {
        "id": "zAKbBPHWd5GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Explain data encoding.\n",
        "\n",
        "Data encoding converts categorical data into numerical form.\n",
        "Techniques:\n",
        "\n",
        "One-hot encoding: Creates binary columns for each category.\n",
        "\n",
        "Label encoding: Assigns an integer to each category."
      ],
      "metadata": {
        "id": "gvkm9dRjeTlw"
      }
    }
  ]
}